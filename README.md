# AMD-Pervasive-AI
  The code of project.
  The HLS pragma code and the weigts files are based on [Edge-MoE](https://github.com/sharc-lab/Edge-MoE/tree/main)
  
## Citation
```bibtex
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{sarkar2023edge,
  title={Edge-moe: Memory-efficient multi-task vision transformer architecture with task-level sparsity via mixture-of-experts},
  author={Sarkar, Rishov and Liang, Hanxue and Fan, Zhiwen and Wang, Zhangyang and Hao, Cong},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)},
  pages={01--09},
  year={2023},
  organization={IEEE}
}
```
